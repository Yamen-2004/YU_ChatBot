import json
import re
from pathlib import Path
from sentence_transformers import SentenceTransformer

# Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø¹Ù†Ø¯ÙƒØŒ Ù…Ø´ Ù…Ø³Ø§Ø±Ø§Øª ÙÙ„Ø³ÙÙŠØ©
CHUNK_FILE = Path("C:/Users/yamen/Downloads/chunking_data.json")
OUTPUT_FILE = Path("C:/Users/yamen/Downloads/embedded_chunks.json")

# ØªØ­Ù…ÙŠÙ„ model embedding
model = SentenceTransformer("all-mpnet-base-v2")

#  Ù‚Ø±Ø§Ø¡Ø© data ÙƒÙ€ JSON array
data = json.loads(CHUNK_FILE.read_text(encoding="utf-8"))

if not isinstance(data, list):
    print("âŒ Ø§Ù„Ø¯Ø§ØªØ§ Ù…Ø´ array! Ø´ÙŠÙ‘Ùƒ Ø§Ù„ÙØ§ÙŠÙ„.")
    exit()

#  embedding Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ ÙÙ‚Ø·
texts = [re.sub(r"\s+", " ", rec.get("text", "")).strip() for rec in data]
vectors = model.encode(texts)

#  Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…ØªØ¬Ù‡ Ù„ÙƒÙ„ record
for i, rec in enumerate(data):
    rec["embedding"] = vectors[i].tolist()

#  Ø­ÙØ¸ Ø§Ù„ÙØ§ÙŠÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
OUTPUT_FILE.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

print("âœ… embedding Ø®Ù„Øµ. Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ø·Ø¹:", len(data))
print("ğŸ“Œ Ù…Ø«Ø§Ù„ Ø£ÙˆÙ„ vector Ø·ÙˆÙ„ Ø£Ø¨Ø¹Ø§Ø¯Ù‡:", len(data[0]["embedding"]))
